# ğŸŒ± UNet++â€‘Replication

This repository contains a PyTorch implementation of **UNet++**, designed to replicate the nested skipâ€‘path architecture and deep supervision strategy for semantic segmentation tasks.  

- Implements full **nested skip pathways** with **dense convolution blocks** (as described in Eq.(1) of the paper).  
- Supports **deep supervision**: segmentation heads on multiple decoder levels for flexible training / pruning.  
- Pure architecture-level code, so you can plug in your own data loader & loss / training loop.  

---

## ğŸ–¼ï¸ Overview â€“ UNet++ Architecture

![](images/figuremix.jpg)  
*FigureÂ 2:* Qualitative comparison between **U-Net**, **wide U-Net**, and **UNet++**, showing segmentation results for **polyp**, **liver**, and **cell nuclei** datasets (2D-only for clear visualization).  

>UNet++ is a nested U-Net for semantic segmentation. Dense skip pathways connect encoder and decoder nodes, reducing the semantic gap and improving feature alignment. Deep >supervision allows outputs at multiple decoder levels for flexible training or faster inference.

![](images/math.jpg)  
*Mathematical formulation:* Eq.(1) defines how each node combines features from encoder or lowerâ€‘level upsampled maps; deep supervision at multiple depths uses combined BCE + Dice loss.  

---

## ğŸ—ï¸ Repo Structure

```text
UNet++-Replication/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ layers/
â”‚   â”‚   â”œâ”€â”€ conv_layer.py               # Basic conv + BN + activation blocks  
â”‚   â”‚   â”œâ”€â”€ dense_skip_block.py         # Dense convolution block along skip pathways  
â”‚   â”‚   â”œâ”€â”€ upsample_layer.py           # Upsampling operations for decoder / skip connections  
â”‚   â”‚   â”œâ”€â”€ deep_supervision_head.py    # 1Ã—1 conv + activation producing segmentation outputs at multiple depths  
â”‚   â”œâ”€â”€ blocks/
â”‚   â”‚   â”œâ”€â”€ encoder_block.py            # Encoder stage: convs + downâ€‘sampling  
â”‚   â”‚   â”œâ”€â”€ decoder_block.py            # Decoder stage (nonâ€‘nested paths)  
â”‚   â”‚   â””â”€â”€ nested_skip_unit.py         # Implements node computation \(X_{i,j}\) according to Eq.(1)  
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ unetpp_model.py             # Highâ€‘level UNet++ model assembly: encoder, nested skips, decoder, deep supervision heads  
â”‚   â””â”€â”€ config.py                       # Default hyperparameters: input channels, depth, base filters, etc.  
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ figuremix.jpg                     
â”‚   â”‚                   
â”‚   â””â”€â”€ math.jpg                        # key equations and mathematical overview  
â”œâ”€â”€ requirements.txt                    # minimal dependencies  
â””â”€â”€ README.md                           # this file  
```
---


## ğŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)
